"""
Integration tests for orchestrator downstream dependency resolution.

These tests use mocked agents (no real LLM / Gemini API key required).
They exercise the full orchestrator loop: state seeding → process_request
→ assert state mutations and agent execution order.

Run with:
    python -m pytest tests/integration/test_orchestrator_downstream.py -v
or:
    python tests/integration/test_orchestrator_downstream.py
"""

from __future__ import annotations

import asyncio
import sys
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock

import pytest

sys.path.insert(0, str(Path(__file__).resolve().parents[2]))

from src.orchestrator.execution_plan import ExecutionPlan
from src.orchestrator.master_agent import MasterOrchestrator
from src.state.project_state import ArchitectureDefinition, ProjectState, Requirements
from src.state.state_manager import StateManager
from src.storage.memory_store import InMemoryPersistenceAdapter


# ---------------------------------------------------------------------------
# Fake agents
# ---------------------------------------------------------------------------

class FakeArchitectAgent:
    """Simulates project_architect: produces an architecture state_delta."""

    def __init__(self, tech_stack: dict | None = None):
        self._tech_stack = tech_stack or {"backend": "Python/FastAPI", "frontend": "React"}

    async def process(self, input_data: dict) -> dict:
        return {
            "state_delta": {
                "architecture": {
                    "tech_stack": self._tech_stack,
                    "tech_stack_rationale": "Generated by fake architect",
                    "data_schema": None,
                    "system_diagram": None,
                    "api_design": [],
                    "deployment_strategy": None,
                }
            },
            "summary": f"Architecture generated with stack: {self._tech_stack}",
        }


class FakeRequirementsCollector:
    async def process_message(self, user_input, requirements_state, history):
        return {"response": "Requirements noted.", "requirements": None}


class FakeExecutionPlannerAgent:
    """Simulates execution_planner agent: records that it was called."""

    def __init__(self):
        self.call_count = 0
        self.last_input = None

    async def process(self, input_data: dict) -> dict:
        self.call_count += 1
        self.last_input = input_data
        return {
            "state_delta": {},
            "summary": "Execution plan generated.",
        }


class CapturingRegistry:
    """Registry that tracks which agents were instantiated/called."""

    def __init__(self, agents: dict):
        self._agents = agents  # agent_id -> agent instance
        self.called: list[str] = []

    def get_agent(self, agent_id: str):
        agent = self._agents.get(agent_id)
        if agent is not None:
            self.called.append(agent_id)
        return agent


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _make_orchestrator(state_manager, project_state, registry, plan):
    """Build an orchestrator with _graph.ainvoke patched to return a fixed plan."""
    orch = MasterOrchestrator.__new__(MasterOrchestrator)
    orch.state = state_manager
    orch.registry = registry

    mock_graph = MagicMock()
    mock_graph.ainvoke = AsyncMock(return_value={
        "project_state": project_state,
        "plan": plan,
        "intent": {"primary_intent": "architecture_design", "requires_agents": ["project_architect"], "confidence": 0.9},
        "error": None,
    })
    orch._graph = mock_graph
    return orch


def _plan_with_agents(*agent_ids: str) -> ExecutionPlan:
    from src.orchestrator.agent_store import get_agent_by_id
    plan = ExecutionPlan()
    for aid in agent_ids:
        entry = get_agent_by_id(aid)
        plan.add_task(agent_id=aid, required_context=(entry or {}).get("requires") or [])
    return plan


# ---------------------------------------------------------------------------
# Tests
# ---------------------------------------------------------------------------

@pytest.mark.asyncio
async def test_downstream_execution_planner_runs_after_architect():
    """
    3.5 core: when project_architect is in the plan, execution_planner is
    appended downstream. Both appear in agent_results in the correct order.
    execution_planner is 'skipped' (placeholder not yet wired) but is
    still planned and appears after project_architect in the results list.
    """
    session_id = "test-35-downstream"
    persistence = InMemoryPersistenceAdapter()
    sm = StateManager(persistence)

    seed = ProjectState(
        session_id=session_id,
        current_phase="requirements_complete",
        requirements=Requirements(functional=["Login", "Dashboard"], constraints=["Python"]),
    )
    await persistence.save(session_id, seed.model_dump())

    fake_exec_planner = FakeExecutionPlannerAgent()
    registry = CapturingRegistry({
        "project_architect": FakeArchitectAgent(),
        "execution_planner": fake_exec_planner,
    })

    # Plan includes both agents (as downstream resolution would produce)
    plan = _plan_with_agents("project_architect", "execution_planner")
    orch = _make_orchestrator(sm, seed, registry, plan)

    response = await orch.process_request("Design the architecture", session_id)

    # project_architect must have been fetched from registry
    assert "project_architect" in registry.called, "project_architect should have been fetched"
    # execution_planner must have been fetched from registry (even if _run_agent skips it)
    assert "execution_planner" in registry.called, "execution_planner should have been fetched"
    # Order: project_architect before execution_planner
    assert registry.called.index("project_architect") < registry.called.index("execution_planner"), \
        "project_architect must be fetched before execution_planner"

    # Both should appear in agent_results
    result_ids = [ar["agent_id"] for ar in response["agent_results"]]
    assert "project_architect" in result_ids
    assert "execution_planner" in result_ids
    assert result_ids.index("project_architect") < result_ids.index("execution_planner"), \
        "project_architect must appear before execution_planner in agent_results"

    print("  PASS: downstream — execution_planner planned after project_architect, both in agent_results")


@pytest.mark.asyncio
async def test_phase_transitions_after_architect():
    """
    3.5 + 3.2: after project_architect runs, current_phase becomes architecture_complete.
    """
    session_id = "test-35-phase"
    persistence = InMemoryPersistenceAdapter()
    sm = StateManager(persistence)

    seed = ProjectState(
        session_id=session_id,
        current_phase="requirements_complete",
        requirements=Requirements(functional=["Auth"]),
    )
    await persistence.save(session_id, seed.model_dump())

    registry = CapturingRegistry({"project_architect": FakeArchitectAgent()})
    plan = _plan_with_agents("project_architect")
    orch = _make_orchestrator(sm, seed, registry, plan)

    await orch.process_request("Generate architecture", session_id)

    state_dict = await persistence.get(session_id)
    assert state_dict["current_phase"] == "architecture_complete", \
        f"Expected architecture_complete, got {state_dict['current_phase']}"
    print("  PASS: phase transition → architecture_complete after project_architect")


@pytest.mark.asyncio
async def test_change_request_reruns_downstream():
    """
    3.5 change request: seed state with existing architecture (Node.js),
    then simulate a change request that re-runs project_architect with a new
    stack (Python) and also triggers execution_planner downstream.
    """
    session_id = "test-35-change"
    persistence = InMemoryPersistenceAdapter()
    sm = StateManager(persistence)

    # Seed: project already has a Node.js architecture
    seed = ProjectState(
        session_id=session_id,
        current_phase="architecture_complete",
        requirements=Requirements(functional=["Login"], constraints=["Node.js"]),
        architecture=ArchitectureDefinition(tech_stack={"backend": "Node.js/Express"}),
    )
    await persistence.save(session_id, seed.model_dump())

    # Change request: switch to Python
    new_architect = FakeArchitectAgent(tech_stack={"backend": "Python/FastAPI"})
    fake_exec_planner = FakeExecutionPlannerAgent()
    registry = CapturingRegistry({
        "project_architect": new_architect,
        "execution_planner": fake_exec_planner,
    })

    plan = _plan_with_agents("project_architect", "execution_planner")
    orch = _make_orchestrator(sm, seed, registry, plan)

    response = await orch.process_request("Change backend to Python/FastAPI", session_id)

    # Both agents should have run
    assert "project_architect" in registry.called
    assert "execution_planner" in registry.called

    # Architecture state should reflect the new stack
    state_dict = await persistence.get(session_id)
    tech_stack = state_dict.get("architecture", {}).get("tech_stack", {})
    assert tech_stack.get("backend") == "Python/FastAPI", \
        f"Expected Python/FastAPI, got {tech_stack}"

    # Phase should have advanced
    assert state_dict["current_phase"] == "architecture_complete"
    print(f"  PASS: change request — both agents re-ran, stack updated to {tech_stack}")


@pytest.mark.asyncio
async def test_agent_results_populated_for_all_ran_agents():
    """
    3.5 + 3.4: agent_results in response contains entries for every agent in the plan.
    """
    session_id = "test-35-agent-results"
    persistence = InMemoryPersistenceAdapter()
    sm = StateManager(persistence)

    seed = ProjectState(
        session_id=session_id,
        current_phase="requirements_complete",
        requirements=Requirements(functional=["Auth"]),
    )
    await persistence.save(session_id, seed.model_dump())

    fake_exec_planner = FakeExecutionPlannerAgent()
    registry = CapturingRegistry({
        "project_architect": FakeArchitectAgent(),
        "execution_planner": fake_exec_planner,
    })

    plan = _plan_with_agents("project_architect", "execution_planner")
    orch = _make_orchestrator(sm, seed, registry, plan)

    response = await orch.process_request("Design and plan", session_id)

    agent_result_ids = [ar["agent_id"] for ar in response["agent_results"]]
    assert "project_architect" in agent_result_ids
    assert "execution_planner" in agent_result_ids

    for ar in response["agent_results"]:
        assert ar["status"] in ("success", "skipped", "error")
    print(f"  PASS: agent_results populated for all agents: {agent_result_ids}")


@pytest.mark.asyncio
async def test_manual_mode_only_runs_selected_agent():
    """
    3.5 + 3.4 manual mode: only the selected agent (and its upstream) runs.
    Downstream agents are NOT appended in manual mode.
    """
    session_id = "test-35-manual"
    persistence = InMemoryPersistenceAdapter()
    sm = StateManager(persistence)

    seed = ProjectState(
        session_id=session_id,
        current_phase="requirements_complete",
        requirements=Requirements(functional=["Auth"]),
    )
    await persistence.save(session_id, seed.model_dump())

    fake_exec_planner = FakeExecutionPlannerAgent()
    registry = CapturingRegistry({
        "project_architect": FakeArchitectAgent(),
        "execution_planner": fake_exec_planner,
    })

    # In manual mode, _graph is never called — orchestrator builds plan itself
    orch = MasterOrchestrator.__new__(MasterOrchestrator)
    orch.state = sm
    orch.registry = registry
    mock_graph = MagicMock()
    mock_graph.ainvoke = AsyncMock(side_effect=AssertionError("graph should not be called in manual mode"))
    orch._graph = mock_graph

    response = await orch.process_request(
        "Run architect only",
        session_id,
        agent_selection_mode="manual",
        selected_agent_id="project_architect",
    )

    # Only project_architect should have run (execution_planner is downstream, not upstream)
    assert "project_architect" in registry.called
    assert "execution_planner" not in registry.called, \
        "execution_planner should NOT run in manual mode (downstream not expanded)"
    assert response["intent"]["primary_intent"] == "manual"
    print("  PASS: manual mode ran only project_architect, not downstream execution_planner")


# ---------------------------------------------------------------------------
# Standalone runner (no pytest needed)
# ---------------------------------------------------------------------------
if __name__ == "__main__":
    tests = [
        test_downstream_execution_planner_runs_after_architect,
        test_phase_transitions_after_architect,
        test_change_request_reruns_downstream,
        test_agent_results_populated_for_all_ran_agents,
        test_manual_mode_only_runs_selected_agent,
    ]

    async def run_all():
        print("\n=== Part 3.5 — Integration Tests (Change Request / Downstream) ===\n")
        passed = 0
        for test in tests:
            print(f"Running {test.__name__}...")
            try:
                await test()
                passed += 1
            except AssertionError as e:
                print(f"  FAIL: {e}")
            except Exception as e:
                import traceback
                print(f"  ERROR: {type(e).__name__}: {e}")
                traceback.print_exc()
        print(f"\n{'='*60}")
        print(f"Results: {passed}/{len(tests)} passed")
        if passed < len(tests):
            sys.exit(1)

    asyncio.run(run_all())
